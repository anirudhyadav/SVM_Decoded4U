{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4563f93",
   "metadata": {},
   "source": [
    "# üß† Support Vector Machine (SVM) - Exhaustive Master Notebook\n",
    "\n",
    "Welcome to the **most exhaustive SVM tutorial notebook**!\n",
    "We cover deep theory, math, intuition, visualizations, code, hyperparameters, evaluation metrics, tuning, and more.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2829f40f",
   "metadata": {},
   "source": [
    "# üìç 1. Learning Roadmap\n",
    "\n",
    "**Flow:**\n",
    "```\n",
    "Real-world intuition ‚ûî Why SVM ‚ûî Core Idea ‚ûî Math ‚ûî Margins ‚ûî Support Vectors ‚ûî Kernels ‚ûî Hinge Loss ‚ûî Code ‚ûî Error Analysis ‚ûî Tuning ‚ûî Roadmap ‚ûî Final Projects\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498b3686",
   "metadata": {},
   "source": [
    "# ‚ú® 2. Introduction to SVM\n",
    "- SVM = **Separating data with maximum margin**.\n",
    "- Used in: Face detection, OCR, Bioinformatics, Text classification (spam detection).\n",
    "- Goal: Draw a decision boundary that **separates classes as wide as possible**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19c209",
   "metadata": {},
   "source": [
    "# üß† 3. Why Do We Need SVM?\n",
    "- Logistic Regression struggles with complex boundaries.\n",
    "- KNN sensitive to noise and scaling.\n",
    "- SVM offers **robust generalization** even in high-dimensional spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4002f",
   "metadata": {},
   "source": [
    "# üî• 4. Core Idea Behind SVM: Maximize the Margin\n",
    "- Margin = Distance between decision boundary and nearest points.\n",
    "- Wider margin ‚ûî Better generalization ‚ûî Lower overfitting risk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137cc46a",
   "metadata": {},
   "source": [
    "# üî¢ 5. Mathematical Formulation\n",
    "Minimize:\n",
    "\\[ \\frac{1}{2} \\|w\\|^2 \\]\n",
    "Subject to:\n",
    "\\[ y_i (w \\cdot x_i + b) \\geq 1 \\]\n",
    "Where:\n",
    "- \\(w\\) = weight vector\n",
    "- \\(b\\) = bias\n",
    "- \\(y_i\\) = label (+1 or -1)\n",
    "- \\(x_i\\) = feature vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd77ffba",
   "metadata": {},
   "source": [
    "# üìà 6. Visualizing Hyperplanes & Margins\n",
    "```\n",
    "Class A (o o o)\n",
    "\n",
    "     | Margin |\n",
    "------------------- Hyperplane -------------------\n",
    "     | Margin |\n",
    "\n",
    "Class B (x x x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedcf32c",
   "metadata": {},
   "source": [
    "# üßÆ 7. Support Vectors Intuition\n",
    "- Support vectors are closest points.\n",
    "- Define decision boundary and margin.\n",
    "- Without them, boundary would change!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5df5a0",
   "metadata": {},
   "source": [
    "# üß© 8. Hard Margin vs Soft Margin\n",
    "\n",
    "| Aspect | Hard Margin | Soft Margin |\n",
    "|:---|:---|:---|\n",
    "| Definition | Perfect separation | Allow some misclassifications |\n",
    "| Use Case | Clean data | Noisy real-world data |\n",
    "| Controlled by | Strict constraint | Penalty term (C) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0026a70",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è 9. Hyperparameters of SVM (Exhaustive)\n",
    "\n",
    "### C (Regularization)\n",
    "- Low C ‚ûî Wider margin, more tolerance\n",
    "- High C ‚ûî Narrow margin, less tolerance\n",
    "- Tune via GridSearch\n",
    "\n",
    "### Kernel\n",
    "- 'linear', 'poly', 'rbf', 'sigmoid'\n",
    "- Start with RBF\n",
    "\n",
    "### Gamma\n",
    "- Low gamma ‚ûî Far points influence more\n",
    "- High gamma ‚ûî Only nearby points matter\n",
    "\n",
    "### Degree (for poly)\n",
    "- Degree of polynomial transformation\n",
    "- Rarely > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ecf9e3",
   "metadata": {},
   "source": [
    "# üîÅ 10. Kernel Trick\n",
    "- Map data into higher dimensions.\n",
    "- RBF Kernel: Infinite dimensions.\n",
    "- Polynomial Kernel: Explicit high-degree mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c9ba9",
   "metadata": {},
   "source": [
    "# üîç 11. Hinge Loss Function\n",
    "Loss =\n",
    "\\[ \\max(0, 1 - y_i (w \\cdot x_i + b)) \\]\n",
    "- No penalty if correctly classified outside margin.\n",
    "- Linear penalty inside margin or wrong side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = np.linspace(-2, 3, 100)\n",
    "hinge_loss = np.maximum(0, 1 - scores)\n",
    "\n",
    "plt.plot(scores, hinge_loss, label=\"Hinge Loss\")\n",
    "plt.axvline(x=1, linestyle=\"--\", color=\"grey\", label=\"Margin\")\n",
    "plt.title(\"Hinge Loss vs Score\")\n",
    "plt.xlabel(\"Score (y*(w.x+b))\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e75a3",
   "metadata": {},
   "source": [
    "# üìä 12. Evaluation Metrics (Exhaustive)\n",
    "\n",
    "| Metric | Formula | When Best |\n",
    "|:---|:---|:---|\n",
    "| Accuracy | (TP+TN)/(TP+TN+FP+FN) | Balanced datasets |\n",
    "| Precision | TP/(TP+FP) | FP costly |\n",
    "| Recall | TP/(TP+FN) | FN costly |\n",
    "| F1-Score | 2(Precision*Recall)/(Precision+Recall) | Imbalanced data |\n",
    "| ROC-AUC | Probability ranking | Binary classification |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa263c92",
   "metadata": {},
   "source": [
    "# üõ†Ô∏è 13. Hands-On SVM (Easy) - Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02453678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "iris = datasets.load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Build SVM\n",
    "model = SVC(kernel='rbf', C=1, gamma='scale')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7145c2",
   "metadata": {},
   "source": [
    "# üîé 14. Code Walkthrough\n",
    "- Load Iris data.\n",
    "- Split train/test.\n",
    "- Scale features (important for SVM).\n",
    "- Build SVM (RBF kernel).\n",
    "- Train and predict.\n",
    "- Evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83b754",
   "metadata": {},
   "source": [
    "# üéØ 15. Hyperparameter Tuning via GridSearchCV\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01], 'kernel': ['rbf', 'poly']}\n",
    "grid = GridSearchCV(SVC(), param_grid, verbose=2, cv=3)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09890c89",
   "metadata": {},
   "source": [
    "# üìâ 16. Error Analysis\n",
    "- Plot misclassified points.\n",
    "- Analyze support vectors.\n",
    "- Study decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2129ce",
   "metadata": {},
   "source": [
    "# üö® 17. Common Mistakes\n",
    "- No feature scaling ‚ûî Poor model.\n",
    "- Wrong kernel choice ‚ûî Poor separation.\n",
    "- Too small or too large C ‚ûî Under/Overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bcd705",
   "metadata": {},
   "source": [
    "# üß≠ 18. Where SVM Fits\n",
    "- Small/Medium datasets.\n",
    "- High-dimensional sparse spaces (text, bioinformatics).\n",
    "- Needs scaling always."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6728d",
   "metadata": {},
   "source": [
    "# üéØ 19. Final Takeaways Checklist\n",
    "‚úÖ Maximize margin.\n",
    "‚úÖ Use support vectors.\n",
    "‚úÖ Tune hyperparameters carefully.\n",
    "‚úÖ Scale data always."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb2a7a2",
   "metadata": {},
   "source": [
    "# üöÄ 20. Mini Projects\n",
    "- Handwritten digits classification (MNIST)\n",
    "- Spam mail classification\n",
    "- Plant disease detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd3614",
   "metadata": {},
   "source": [
    "# ‚ö° 21. SVM vs Logistic Regression vs Perceptron\n",
    "\n",
    "| Feature | SVM | Logistic Regression | Perceptron |\n",
    "|:---|:---|:---|:---|\n",
    "| Loss | Hinge | Log Loss | Perceptron Loss |\n",
    "| Goal | Maximize Margin | Maximize Likelihood | Correct Errors |\n",
    "| Probabilities | No (unless calibrated) | Yes | No |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1c7a3",
   "metadata": {},
   "source": [
    "# üìú 22. Short History\n",
    "- Invented by Vladimir Vapnik.\n",
    "- Popularized in the 1990s.\n",
    "- Rooted in Statistical Learning Theory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acb89f",
   "metadata": {},
   "source": [
    "# üßπ 23. Best Practices Summary\n",
    "- Scale features.\n",
    "- Start with RBF kernel.\n",
    "- Use GridSearch.\n",
    "- Watch for overfitting with C, gamma tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2cf5f",
   "metadata": {},
   "source": [
    "# üß† 24. Bonus (Advanced): Dual Form + SMO\n",
    "- Dual problem: Solves for Œ± instead of w.\n",
    "- SMO algorithm: Efficient method for solving dual form for large datasets."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
